## Intuitive-Gesture-Drone-Control

Team Guardian (SFU Unmanned Aerial Veicle Team) research project in Computer Vision.

### Getting Started
1. Clone the project 
```
git clone https://github.com/tsa87/Intuitive-Gesture-Drone-Control.git
```
2. Install the prerequisites
```
pip install argparse
pip install numpy
pip install opencv-contrib-python
pip install scipy
pip install tensorflow
```
3. Run the demo
```
# on video file
python demo.py -v PATH_TO_VIDEO
```
```
# from camera stream
python demo.py
```

### Demo
![](https://media.giphy.com/media/MB0S2CQ7dfTXFIbpTy/giphy.gif)

![](https://media.giphy.com/media/dWNUY5N1c617vimo2c/giphy.gif)

### Author

* **Tony Shen** - *Initial work* - [TeamGuardian](https://github.com/Team-Guardian)

### License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

### Acknowledgment

* **Victor Dibia** - *Real-time Hand-Detection using Neural Networks (SSD) on Tensorflow, (2017)*  
GitHub repository, https://github.com/victordibia/handtracking



